{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "WM225C0CbtGe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SojiroNishimura/deeplearning-from-scratch/blob/master/chapter4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89gk1dhtw7vv",
        "colab_type": "text"
      },
      "source": [
        "# ニューラルネットワークの学習\n",
        "ニューラルネットワークの学習とは、訓練データから最適な重みパラメータの値を自動的に獲得することを指す。最適な重みパラメータとは、未知の入力に対して可能な限り高い確率で正解を出力するような値のことである。訓練データに対してのみではなく、未知の入力に対しても高い正解率となる性質を **汎化能力** という。機械学習の目的はこの汎化能力を獲得することである。\n",
        "\n",
        "なお訓練データにのみ高い正解率となり未知の入力に対して正解率が低い状態を **過学習** という。これは訓練データに対して過度に最適化された結果、高い汎化能力を得られていない状態である。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57T76NE58d8z",
        "colab_type": "text"
      },
      "source": [
        "## 損失関数\n",
        "ニューラルネットワークの性能を計る指標として **損失関数(loss function)** を使用する。これは正解率の低さを計る指標であり、損失関数の出力を最小化することによって正解率が最大となる重みを計算することが機械学習における「学習」の意味である。\n",
        "\n",
        "ここでの損失とは、入力データに対してニューラルネットワークの出力が不正解だった場合を表し、出力と教師データとの「誤差」をまとめたものである。損失関数を最小化する=出力と教師データとの誤差を最小にするということである。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4Dd8sLdAfg7",
        "colab_type": "text"
      },
      "source": [
        "### 2乗和誤差\n",
        "$E=\\frac{1}{2}\\displaystyle \\sum_{k}(y_{k}-t_{k})^2$\n",
        "\n",
        "* NNの各出力と正解ラベルの差の2乗を合計して1/2する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIjizQXw95Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3jGncft-D0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_squared_error(y, t):\n",
        "  return 0.5 * np.sum((y-t)**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRsK6yGv-R3h",
        "colab_type": "code",
        "outputId": "609f7657-b9fb-4d62-e652-3331f27e7c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 正解ラベルに対応する出力が最も高い場合（正解=2）\n",
        "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "mean_squared_error(np.array(y), np.array(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09750000000000003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWxj277Y_Fcd",
        "colab_type": "code",
        "outputId": "315a8c39-6edf-499b-f561-2c2095a7670a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 正解ラベルに対応する出力が低い場合（正解=2）\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "mean_squared_error(np.array(y), np.array(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tuE4BTFBiTI",
        "colab_type": "text"
      },
      "source": [
        "### 交差エントロピー誤差\n",
        "$E=-\\displaystyle \\sum_{k}t_{k}\\log{y_{k}}$\n",
        "\n",
        "* tはOne-hot表現\n",
        "* tのうち正解ラベル以外の値は0なので、実質的にNNの正解ラベルに対応するインデックスにおける出力の対数をとることに等しい\n",
        "* `np.log(0)`が発生した場合、値が`-inf`になるのを避けるため、微小な値deltaを追加する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Sbxo0B_k3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy_error(y, t):\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t * np.log(y + delta))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1dyBRUAARf3",
        "colab_type": "code",
        "outputId": "fcc27b84-26c9-4824-fe7b-45029febf02a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 正解ラベルに対応する出力が最も高い場合（正解=2）\n",
        "y = [0.1, 0.5, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.510825457099338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp8Kx46SKtby",
        "colab_type": "code",
        "outputId": "0b333142-4edb-4c6a-a204-a0c9b2146488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 正解ラベルに対応する出力が低い場合（正解=2）\n",
        "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.302584092994546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s89gtvH4L6QR",
        "colab_type": "text"
      },
      "source": [
        "### ミニバッチ学習\n",
        "上記2つの損失関数は個別のデータに対応する値を求めるもの。複数のデータに適用するためには複数のデータをまとめて計算できるように拡張する必要がある。\n",
        "\n",
        "$E=-\\frac{1}{n}\\displaystyle \\sum_{n}\\displaystyle \\sum_{k}t_{nk}\\log{y_{nk}}$\n",
        "\n",
        "交差エントロピー誤差をn個のデータに適用すると上記の式になる。$\\frac{1}{n}$によって1個あたりの平均損失関数を求めることができる。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvGKR6DuN-Eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldB1Ri9nPNn7",
        "colab_type": "code",
        "outputId": "435051f7-6a15-42cf-a468-99253ebfed08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjKO2RFgPnQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_normalized = list(map(lambda arr: arr.flatten(), x_train))\n",
        "x_test_normalized = list(map(lambda arr: arr.flatten(), x_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trcOG1uVTXXP",
        "colab_type": "code",
        "outputId": "1f0cdd32-680d-43ab-a198-4640aac5394e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(x_train_normalized).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZN5_V7ETf5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_normalized = np.array(x_train_normalized)\n",
        "x_test_normalized = np.array(x_test_normalized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tASBcTXpTnkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_labels = len(np.unique(y_train))  # 分類クラスの数 = 10\n",
        "y_train_onehot = np.eye(n_labels)[y_train]           # one hot表現に変換\n",
        "y_test_onehot = np.eye(n_labels)[y_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9OpOGtWUL0Z",
        "colab_type": "code",
        "outputId": "381d92ca-6e1f-4557-e7d4-abfe280548a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train_onehot.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpLrv0Y9UOK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = x_train_normalized.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "x_batch = x_train_normalized[batch_mask]\n",
        "y_batch = y_train_onehot[batch_mask]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GUsUgNzUuxi",
        "colab_type": "code",
        "outputId": "851bd2da-7ffa-4b06-de70-24af4d66d321",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.random.choice(60000, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([32956,  7892,   865, 51437,   714, 43917, 26378, 41214,  5766,\n",
              "       46053])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1nvYJEcU0Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy_error2(y, t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "    \n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(t * np.log(y + 1e-7)) / batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU78yR_5-r2R",
        "colab_type": "text"
      },
      "source": [
        "### なぜ損失関数を計算するのか？\n",
        "ニューラルネットワークの性能を計るために損失関数を使うのは、そのほうが最適化問題を解くのに有用だからである。もし正解率を指標にすると、パラメータを更新してもほとんど正解率は変わらず、各パラメータごとの影響度も判別できない。しかし損失関数の最小化を考えると、各パラメータごとに偏微分することによって、パラメータごとの影響度と全体の勾配を求めることができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jRdlIatWENJ",
        "colab_type": "text"
      },
      "source": [
        "## 数値微分\n",
        "ある関数が極小に変化した場合の変化量を求める。\n",
        "\n",
        "$\\frac{df(x)}{dx}=\\displaystyle \\lim_{h \\to 0}\\frac{f(x+h)-f(x)}{h}$\n",
        "\n",
        "ただしコンピュータで極小量の計算を行うと誤差が発生するので、xを中心として前後の差分を計算することで誤差を減らす工夫を行う（中心差分）。\n",
        "\n",
        "なお実際に微小な変化量を計算することを**数値微分**といい、数式の整理によって解を得ることを**解析的に解く**と言う。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se3lC_s7WVeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numerical_diff(f, x):\n",
        "  h = 1e-4 # 0.0001\n",
        "  return (f(x+h) - f(x-h)) / (2*h)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odDkLPS9aIlU",
        "colab_type": "text"
      },
      "source": [
        "### 数値微分の例\n",
        "$y=0.01x^2+0.1x$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH0eYwlyZPOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_1(x):\n",
        "  return 0.01*x**2 + 0.1*x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbLj-L92ad_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.arange(0.0, 20.0, 0.1) # 0~20.0まで0.1刻みの配列\n",
        "y = func_1(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4anfuBaNa3uM",
        "colab_type": "code",
        "outputId": "4a9a005b-231f-427c-f095-abd9f84e18c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"f(x)\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crYSxhJXa9w2",
        "colab_type": "code",
        "outputId": "fc18dd30-bc6a-43cd-ba2c-0127a7311f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# x=5, x=10で微分する\n",
        "print(numerical_diff(func_1, 5))\n",
        "print(numerical_diff(func_1, 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1999999999990898\n",
            "0.2999999999986347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM225C0CbtGe",
        "colab_type": "text"
      },
      "source": [
        "### 偏微分の例\n",
        "偏微分=変数が複数ある場合の微分。\n",
        "\n",
        "$f(x_{0}, x_{1})=x^2_{0}+x^2_{1}$\n",
        "\n",
        "各変数に対する偏微分は以下のように表される。\n",
        "\n",
        "$\\frac{\\partial f}{\\partial x_{0}}$, $\\frac{\\partial f}{\\partial x_{1}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ce-uWE4beJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def func_2(x):\n",
        "  return x[0]**2 + x[1]**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsQWKTMtdAnu",
        "colab_type": "code",
        "outputId": "618ad376-5422-4c10-c07b-5561d0c29c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# x0 = 3, x1 = 4のときのx0に対する偏微分\n",
        "def func_tmp1(x0):\n",
        "  return x0*x0 + 4.0**2.0\n",
        "\n",
        "numerical_diff(func_tmp1, 3.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.00000000000378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TLZ3BN8iKLk",
        "colab_type": "code",
        "outputId": "a1bef5c0-666f-4f89-cd2a-e847f01448e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# x0 = 3, x1 = 4のときのx1に対する偏微分\n",
        "def func_tmp2(x1):\n",
        "  return 3.0**2.0 + x1*x1\n",
        "\n",
        "numerical_diff(func_tmp2, 4.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.999999999999119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjfl9GrZiy54",
        "colab_type": "text"
      },
      "source": [
        "## 勾配\n",
        "複数の変数があるとき、すべての変数の偏微分をベクトルとしてまとめたものを**勾配(gradient)**と言い以下のように表記する。\n",
        "\n",
        "$(\\frac{\\partial f}{\\partial x_{0}}, \\frac{\\partial f}{\\partial x_{1}})$\n",
        "\n",
        "勾配は各場所（入力）において、**関数の値を最も減らす方向**を示す。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV15kkA_ic-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numerical_gradient(f, x):\n",
        "  h = 1e-4 # 0.0001\n",
        "  grad = np.zeros_like(x) # xと同じ形状の配列を生成\n",
        "  \n",
        "  for idx in range(x.size):\n",
        "    tmp_val = x[idx]\n",
        "    # f(x+h)の計算\n",
        "    x[idx] = tmp_val + h\n",
        "    fxh1 = f(x)\n",
        "    \n",
        "    # f(x-h)の計算\n",
        "    x[idx] = tmp_val - h\n",
        "    fxh2 = f(x)\n",
        "    \n",
        "    grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "    x[idx] = tmp_val # 値をもとに戻す\n",
        "    \n",
        "  return grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljVhd1Z7ogxm",
        "colab_type": "code",
        "outputId": "86525b3a-a77f-4f38-f257-fccc1111089c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numerical_gradient(func_2, np.array([3.0, 4.0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6., 8.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy9_ENf3o3PS",
        "colab_type": "code",
        "outputId": "bb0d2a39-bf37-4829-b697-2b5b7888226e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numerical_gradient(func_2, np.array([0.0, 2.0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB22CDr7o8KC",
        "colab_type": "code",
        "outputId": "161b551b-92e9-4b41-d1a4-23fac9bc5857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numerical_gradient(func_2, np.array([3.0, 0.0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wile2f7HsHQp",
        "colab_type": "text"
      },
      "source": [
        "### 勾配法\n",
        "関数を最小化する（最小とは限らないが減少させる）ためには、現在の場所から勾配方向に一定距離進み、移動した地点から再度勾配を計算することを一定回数繰り返すことで最小値（あるいは極小値）を求める。これが**勾配法**である。\n",
        "\n",
        "2変数の勾配法は以下のように表される。\n",
        "\n",
        "$x_{0}=x_{0}-\\eta\\frac{\\partial f}{\\partial x_{0}}$\n",
        "\n",
        "$x_{1}=x{1}-\\eta\\frac{\\partial f}{\\partial x_{1}}$\n",
        "\n",
        "\n",
        "$\\eta$は**学習率(learning rate)**と呼ばれ、1回の学習でどれだけパラメータを更新すべきかを決める（=勾配方向への移動量を決める）。\n",
        "\n",
        "学習率は大きすぎても小さすぎても「良い場所」に収束しないので、0.01や0.001などの値を試行錯誤する必要がある。ニューラルネットワークで学習させる重み（パラメータ）とは異なり、学習のために任意に決める必要がある値を**ハイパーパラメータ**と言う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcNprjKDpBH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
        "  x = init_x\n",
        "  \n",
        "  for i in range(step_num):\n",
        "    grad = numerical_gradient(f, x)\n",
        "    x -= lr * grad\n",
        "  \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7N78e94ymUY",
        "colab_type": "code",
        "outputId": "dfe15bdc-ed7e-4317-f763-f5574230e9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(func_2, init_x=init_x, lr=0.1, step_num=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.11110793e-10,  8.14814391e-10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiwqFYbqzPdf",
        "colab_type": "code",
        "outputId": "c526c8a1-fd6d-424d-caca-5ac03bb0ecc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 学習率が大きすぎる場合\n",
        "gradient_descent(func_2, init_x=init_x, lr=10.0, step_num=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.34235971e+12, -3.96091057e+12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM1U0HA5ziPG",
        "colab_type": "code",
        "outputId": "134bd764-88ee-4731-95bf-41ea4151b2fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 学習率が小さすぎる場合\n",
        "gradient_descent(func_2, init_x=init_x, lr=1e-20, step_num=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.34235971e+12, -3.96091057e+12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ09LOlM2nds",
        "colab_type": "text"
      },
      "source": [
        "### ニューラルネットワークに対する勾配\n",
        "$2 \\times 3$の重み$W$だけを持つニューラルネットワークがあり、損失関数を$L$で表した場合、勾配は$\\frac{\\partial L}{\\partial W}$となり、以下の数式で表すことができる。\n",
        "\n",
        "\\\\\n",
        "\n",
        "$W=\n",
        "\\begin{pmatrix}\n",
        "w_{11} & w_{12} & w_{13} \\\\\n",
        "w_{21} & w_{22} & w_{23} \\\\\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$\\frac{\\partial L}{\\partial W}=\n",
        "\\begin{pmatrix}\n",
        "\\frac{\\partial L}{\\partial w_{11}} & \\frac{\\partial L}{\\partial w_{12}} & \\frac{\\partial L}{\\partial w_{13}} \\\\\n",
        "\\frac{\\partial L}{\\partial w_{21}} & \\frac{\\partial L}{\\partial w_{22}} & \\frac{\\partial L}{\\partial w_{23}}\n",
        "\\end{pmatrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmKbM7OVzwPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(a):\n",
        "  c = np.max(a)\n",
        "  exp_a = np.exp(a - c) # オーバーフロー対策\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a / sum_exp_a\n",
        "  \n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCtKUj7I7osw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class simpleNet:\n",
        "  def __init__(self):\n",
        "    self.W = np.random.randn(2, 3) # ガウス分布で初期化\n",
        "    \n",
        "  def predict(self, x):\n",
        "    return np.dot(x, self.W)\n",
        "  \n",
        "  def loss(self, x, t):\n",
        "    z = self.predict(x)\n",
        "    y = softmax(z)\n",
        "    loss = cross_entropy_error2(y, t)\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWknfVX-8HKV",
        "colab_type": "code",
        "outputId": "a156a633-f53b-4bd5-e865-a85619295273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "net = simpleNet()\n",
        "print(net.W)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.13922211  0.6842476  -0.62269829]\n",
            " [-0.52392177  0.46659375  0.06449104]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adNQd2Lx8d-A",
        "colab_type": "code",
        "outputId": "29198d84-f6eb-4df8-f826-ee270d6a0220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)\n",
        "print(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.55506286  0.83048293 -0.31557704]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPRFe6YR8o-Q",
        "colab_type": "code",
        "outputId": "a4c8926f-e19b-421b-eb0d-f27b44c41f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWYrmlgv8tDd",
        "colab_type": "code",
        "outputId": "383a9f16-b41b-4e19-991f-c1c7eb2b37e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = np.array([0, 0, 1])\n",
        "net.loss(x, t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5959075919805443"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVSS0Ev5803p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(W):\n",
        "  return net.loss(x, t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAPqyc-X_Xiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 値を元に戻す\n",
        "        it.iternext()   \n",
        "        \n",
        "    return grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpQomhak_Yr6",
        "colab_type": "code",
        "outputId": "35c729f6-8614-4467-9b85-961309056dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dw = numerical_gradient(f, net.W)\n",
        "print(dw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.09573034  0.38263481 -0.47836515]\n",
            " [ 0.14359551  0.57395222 -0.71754773]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r69gfvAu_uar",
        "colab_type": "code",
        "outputId": "1d8bf3dc-d7ba-4499-f79e-5dc374a46900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# lambda版\n",
        "f = lambda w: net.loss(x, t)\n",
        "dw = numerical_gradient(f, net.W)\n",
        "print(dw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.09573034  0.38263481 -0.47836515]\n",
            " [ 0.14359551  0.57395222 -0.71754773]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtFwKbWwIf5K",
        "colab_type": "text"
      },
      "source": [
        "## 学習アルゴリズムの実装\n",
        "ニューラルネットワークとは、適応可能な（=可変の）重みとバイアスを持つネットワーク構造であり、その重みとバイアスを訓練データに適応するように調整することを「学習」と呼ぶ。\n",
        "\n",
        "ニューラルネットワークの学習アルゴリズムは以下の手順で実装できる。\n",
        "\n",
        "* ミニバッチ\n",
        "  * 訓練データからランダムに一部のデータ（=ミニバッチ）を選び出す\n",
        "  * 選びだしたミニバッチの損失関数の値を減少させるようにする\n",
        "* 勾配の計算\n",
        "  * ミニバッチの損失関数を減らすために各重みパラメータの勾配を求める（=パラメータごとに偏微分する）\n",
        "  * 勾配は損失関数を最も減少させる方向を示す\n",
        "* パラメータの更新\n",
        "  * 重みパラメータを勾配方向に微小量（学習率）だけ更新する。\n",
        "* 繰り返す\n",
        "  * 上記手順を値が収束するか一定の条件（回数or損失関数の減少量が一定以下になる）まで繰り返す\n",
        "  \n",
        "上記手順はミニバッチを無作為（=ランダム）に選んで学習を行うことから**確率的勾配降下法(Stochastic Gradient Descent=SGD)**と呼ばれる。\n",
        "\n",
        "以下では隠れ層が1層の2層ニューラルネットワークを実装する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0vrvMacTdDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV16xzO7CCE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TwoLayerNet:\n",
        "  \n",
        "  def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "    self.params = {}\n",
        "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "    self.params['b1'] = np.zeros(hidden_size)\n",
        "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "    self.params['b2'] = np.zeros(output_size)\n",
        "    \n",
        "  def predict(self, x):\n",
        "    W1, W2 = self.params['W1'], self.params['W2']\n",
        "    b1, b2 = self.params['b1'], self.params['b2']\n",
        "    \n",
        "    a1 = np.dot(x, W1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, W2) + b2\n",
        "    y = softmax(a2)\n",
        "    \n",
        "    return y\n",
        "  \n",
        "  # x: 入力データ, t: 教師データ\n",
        "  def loss(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    \n",
        "    return cross_entropy_error2(y, t)\n",
        "  \n",
        "  def accuracy(self, x, t):\n",
        "    y = self.predict(x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    t = np.argmax(t, axis=1)\n",
        "    \n",
        "    accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "    return accuracy\n",
        "  \n",
        "  # x: 入力データ, t: 教師データ\n",
        "  def numerical_gradient(self, x, t):\n",
        "    loss_W = lambda W: self.loss(x, t)\n",
        "    \n",
        "    grads = {}\n",
        "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "    \n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNCkXEnbP2Yx",
        "colab_type": "code",
        "outputId": "bdcfd452-a132-4280-f5ef-03a12ab3a766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
        "print(net.params['W1'].shape)\n",
        "print(net.params['b1'].shape)\n",
        "print(net.params['W2'].shape)\n",
        "print(net.params['b2'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eez-6gLWTSaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.random.rand(100, 784)\n",
        "y = net.predict(x)\n",
        "# print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffykD4LCTyvH",
        "colab_type": "code",
        "outputId": "8f68fa8f-3ab5-40fe-8d1a-3ca991c7ae33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# 完了まで数分かかるので注意されたし\n",
        "t = np.random.rand(100, 10)\n",
        "grads = net.numerical_gradient(x, t)\n",
        "\n",
        "print(grads['W1'].shape)\n",
        "print(grads['b1'].shape)\n",
        "print(grads['W2'].shape)\n",
        "print(grads['b2'].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJNCZANBX25p",
        "colab_type": "code",
        "outputId": "83122ebf-da5b-4697-d8a2-3494172c3111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# さらに時間がかかる…\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "# ハイパーパラメータ\n",
        "iters_num = 10000\n",
        "train_size = x_train_normalized.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "  batch_mask = np.random.choice(train_size, batch_size)\n",
        "  x_batch = x_train_normalized[batch_mask]\n",
        "  t_batch = y_train_onehot[batch_mask]\n",
        "  \n",
        "  grad = network.numerical_gradient(x_batch, t_batch)\n",
        "  \n",
        "  for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "    network.params[key] -= learning_rate * grad[key]\n",
        "    \n",
        "  loss = network.loss(x_batch, t_batch)\n",
        "  train_loss_list.append(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6uFCAnGXZpZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}